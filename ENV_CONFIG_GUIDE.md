# .env é…ç½®è¯¦ç»†æŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨æ­£ç¡®é…ç½®PaperAgentçš„ç¯å¢ƒå˜é‡ã€‚

## ğŸ“‹ å¿«é€Ÿé…ç½®æ­¥éª¤

### 1. å¤åˆ¶é…ç½®æ–‡ä»¶

```bash
cp .env.example .env
```

### 2. æ ¹æ®æ‚¨çš„ä½¿ç”¨åœºæ™¯é€‰æ‹©é…ç½®æ–¹æ¡ˆ

---

## ğŸ¯ é…ç½®æ–¹æ¡ˆé€‰æ‹©

### æ–¹æ¡ˆA: æœ¬åœ°å…è´¹ä½¿ç”¨ï¼ˆæ¨èæ–°æ‰‹ï¼‰

**ç‰¹ç‚¹**: å®Œå…¨å…è´¹ï¼Œæ— éœ€APIå¯†é’¥ï¼Œä½¿ç”¨æœ¬åœ°LLM

**é…ç½®æ­¥éª¤**:

1. **å®‰è£…Ollama** (å¦‚æœè¿˜æ²¡å®‰è£…)
   ```bash
   # Windows: ä¸‹è½½å®‰è£…
   # https://ollama.ai/download

   # Linux/Mac
   curl -fsSL https://ollama.ai/install.sh | sh
   ```

2. **æ‹‰å–æ¨¡å‹**
   ```bash
   # æ¨è: Llama 3 (7B)
   ollama pull llama3

   # æˆ–è€…ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹
   ollama pull qwen2
   ```

3. **ç¼–è¾‘.envæ–‡ä»¶**
   ```bash
   # LLMé…ç½®
   DEFAULT_LLM_PROVIDER=ollama
   OLLAMA_BASE_URL=http://localhost:11434
   OLLAMA_MODEL=llama3

   # å¯ä»¥ä¸å¡«å†™ä»¥ä¸‹APIå¯†é’¥
   OPENAI_API_KEY=
   ANTHROPIC_API_KEY=

   # æ•°æ®åº“ (ä½¿ç”¨Docker)
   DATABASE_URL=postgresql://paperagent:paperagent_password@postgres:5432/paperagent
   REDIS_URL=redis://redis:6379/0
   ```

4. **å¯åŠ¨æœåŠ¡**
   ```bash
   docker-compose up -d
   ```

âœ… **å®Œæˆï¼ç°åœ¨å¯ä»¥å…è´¹ä½¿ç”¨PaperAgentäº†ï¼**

---

### æ–¹æ¡ˆB: ä½¿ç”¨OpenAI GPT-4ï¼ˆæ¨èæ•ˆæœæœ€å¥½ï¼‰

**ç‰¹ç‚¹**: æ•ˆæœæœ€å¥½ï¼Œéœ€è¦APIå¯†é’¥ï¼ŒæŒ‰ä½¿ç”¨ä»˜è´¹

**é…ç½®æ­¥éª¤**:

1. **è·å–OpenAI APIå¯†é’¥**
   - è®¿é—®: https://platform.openai.com/api-keys
   - åˆ›å»ºæ–°çš„APIå¯†é’¥
   - å¤åˆ¶å¯†é’¥ï¼ˆä»¥ `sk-` å¼€å¤´ï¼‰

2. **ç¼–è¾‘.envæ–‡ä»¶**
   ```bash
   # LLMé…ç½®
   DEFAULT_LLM_PROVIDER=openai
   OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
   OPENAI_MODEL=gpt-4o

   # å¦‚æœä½¿ç”¨GPT-4 Turbo
   # OPENAI_MODEL=gpt-4-turbo-preview

   # å¦‚æœä½¿ç”¨GPT-3.5 (æ›´ä¾¿å®œ)
   # OPENAI_MODEL=gpt-3.5-turbo

   # æ•°æ®åº“é…ç½®
   DATABASE_URL=postgresql://paperagent:paperagent_password@postgres:5432/paperagent
   REDIS_URL=redis://redis:6379/0
   ```

3. **å¯åŠ¨æœåŠ¡**
   ```bash
   docker-compose up -d
   ```

ğŸ’¡ **ä»·æ ¼å‚è€ƒ** (2024å¹´1æœˆ):
- GPT-4: $0.03/1K tokens (è¾“å…¥), $0.06/1K tokens (è¾“å‡º)
- GPT-3.5 Turbo: $0.0005/1K tokens (è¾“å…¥), $0.0015/1K tokens (è¾“å‡º)

---

### æ–¹æ¡ˆC: ä½¿ç”¨Anthropic Claudeï¼ˆæ¨èå¹³è¡¡ï¼‰

**ç‰¹ç‚¹**: æ•ˆæœä¼˜ç§€ï¼Œé€Ÿåº¦å¿«ï¼Œä¸Šä¸‹æ–‡é•¿ï¼Œä»·æ ¼é€‚ä¸­

**é…ç½®æ­¥éª¤**:

1. **è·å–Anthropic APIå¯†é’¥**
   - è®¿é—®: https://console.anthropic.com/
   - åˆ›å»ºAPIå¯†é’¥
   - å¤åˆ¶å¯†é’¥

2. **ç¼–è¾‘.envæ–‡ä»¶**
   ```bash
   # LLMé…ç½®
   DEFAULT_LLM_PROVIDER=anthropic
   ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
   ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

   # å…¶ä»–Claudeæ¨¡å‹é€‰é¡¹
   # ANTHROPIC_MODEL=claude-3-opus-20240229  # æœ€å¼ºä½†æœ€è´µ
   # ANTHROPIC_MODEL=claude-3-haiku-20240307 # æœ€å¿«æœ€ä¾¿å®œ

   # æ•°æ®åº“é…ç½®
   DATABASE_URL=postgresql://paperagent:paperagent_password@postgres:5432/paperagent
   REDIS_URL=redis://redis:6379/0
   ```

3. **å¯åŠ¨æœåŠ¡**
   ```bash
   docker-compose up -d
   ```

ğŸ’¡ **Claudeä¼˜åŠ¿**:
- 200K tokensä¸Šä¸‹æ–‡çª—å£
- ä¼˜ç§€çš„ä»£ç ç”Ÿæˆèƒ½åŠ›
- å¿«é€Ÿå“åº”
- ä»·æ ¼åˆç†

---

## ğŸ“ å®Œæ•´é…ç½®è¯´æ˜

### æ•°æ®åº“é…ç½®

```bash
# ä½¿ç”¨Docker (æ¨è)
DATABASE_URL=postgresql://paperagent:paperagent_password@postgres:5432/paperagent

# ä½¿ç”¨æœ¬åœ°PostgreSQL
# DATABASE_URL=postgresql://username:password@localhost:5432/paperagent

# ä½¿ç”¨SQLite (ä»…å¼€å‘æµ‹è¯•)
# DATABASE_URL=sqlite:///./paperagent.db
```

### Redisé…ç½®

```bash
# ä½¿ç”¨Docker
REDIS_URL=redis://redis:6379/0

# ä½¿ç”¨æœ¬åœ°Redis
# REDIS_URL=redis://localhost:6379/0

# å¸¦å¯†ç çš„Redis
# REDIS_URL=redis://:password@redis:6379/0
```

### LLMè¯¦ç»†é…ç½®

```bash
# OpenAIé…ç½®
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4o                    # æ¨è
# OPENAI_MODEL=gpt-4-turbo-preview    # æ›´å¿«
# OPENAI_MODEL=gpt-3.5-turbo          # æ›´ä¾¿å®œ

# Anthropicé…ç½®
ANTHROPIC_API_KEY=sk-ant-your-api-key
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022  # æ¨è
# ANTHROPIC_MODEL=claude-3-opus-20240229    # æœ€å¼º
# ANTHROPIC_MODEL=claude-3-haiku-20240307   # æœ€å¿«

# Ollamaé…ç½®
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3                    # æ¨è
# OLLAMA_MODEL=qwen2                   # ä¸­æ–‡ä¼˜åŒ–
# OLLAMA_MODEL=mistral                 # å°è€Œå¼º
# OLLAMA_MODEL=codellama               # ä»£ç ä¼˜åŒ–

# é€‰æ‹©é»˜è®¤æä¾›å•†
DEFAULT_LLM_PROVIDER=ollama            # ollama, openai, æˆ– anthropic
```

### æ–‡çŒ®æ£€ç´¢é…ç½®

```bash
# arXivé…ç½®
ARXIV_MAX_RESULTS=50                   # æ¯æ¬¡æœç´¢æœ€å¤šè¿”å›è®ºæ–‡æ•°

# Google Scholar (å¯é€‰)
USE_PROXY=false                        # æ˜¯å¦ä½¿ç”¨ä»£ç†
PROXY_URL=                             # ä»£ç†URL (å¦‚éœ€è¦)
# PROXY_URL=http://proxy.example.com:8080
```

### åº”ç”¨è®¾ç½®

```bash
# åŸºæœ¬ä¿¡æ¯
APP_NAME=PaperAgent
APP_VERSION=1.0.0
DEBUG=true                             # ç”Ÿäº§ç¯å¢ƒè®¾ä¸ºfalse
LOG_LEVEL=INFO                         # DEBUG, INFO, WARNING, ERROR

# æ–‡ä»¶å­˜å‚¨è·¯å¾„
DATA_DIR=./data
PAPERS_DIR=./data/papers
EXPERIMENTS_DIR=./data/experiments
LITERATURE_DIR=./data/literature
OUTPUTS_DIR=./data/outputs
```

### å®‰å…¨é…ç½®

```bash
# å¯†é’¥ (ç”Ÿäº§ç¯å¢ƒå¿…é¡»ä¿®æ”¹ï¼)
SECRET_KEY=your-secret-key-change-this-in-production

# ç”Ÿæˆéšæœºå¯†é’¥:
# python -c "import secrets; print(secrets.token_urlsafe(32))"

# å…è®¸çš„ä¸»æœº
ALLOWED_HOSTS=localhost,127.0.0.1
# ç”Ÿäº§ç¯å¢ƒæ·»åŠ å®é™…åŸŸå:
# ALLOWED_HOSTS=localhost,127.0.0.1,yourdomain.com
```

### æ€§èƒ½é…ç½®

```bash
# ä»»åŠ¡é˜Ÿåˆ—
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# é€Ÿç‡é™åˆ¶
RATE_LIMIT_ENABLED=true
RATE_LIMIT_PER_MINUTE=60               # æ¯åˆ†é’Ÿè¯·æ±‚é™åˆ¶

# å¹¶å‘é…ç½®
MAX_CONCURRENT_TASKS=5                 # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°

# ä¼šè¯é…ç½®
SESSION_TIMEOUT=3600                   # ä¼šè¯è¶…æ—¶ (ç§’)
```

### LLMå‚æ•°è°ƒä¼˜

```bash
# ç”Ÿæˆå‚æ•°
MAX_TOKENS=4096                        # æœ€å¤§ç”Ÿæˆtokenæ•°
TEMPERATURE=0.7                        # æ¸©åº¦ (0-1, è¶Šé«˜è¶Šéšæœº)
TOP_P=0.9                             # æ ¸é‡‡æ ·å‚æ•°

# è°ƒä¼˜å»ºè®®:
# - åˆ›æ„å†™ä½œ: TEMPERATURE=0.8-0.9
# - ä»£ç ç”Ÿæˆ: TEMPERATURE=0.2-0.4
# - æ•°æ®åˆ†æ: TEMPERATURE=0.3-0.5
# - å­¦æœ¯å†™ä½œ: TEMPERATURE=0.6-0.7 (æ¨è)
```

---

## ğŸ”§ ç‰¹æ®Šåœºæ™¯é…ç½®

### 1. ç¦»çº¿ä½¿ç”¨ï¼ˆæ— äº’è”ç½‘ï¼‰

```bash
# ä½¿ç”¨æœ¬åœ°Ollama
DEFAULT_LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# ç¦ç”¨åœ¨çº¿æ–‡çŒ®æœç´¢
USE_PROXY=false

# ä½¿ç”¨æœ¬åœ°æ•°æ®åº“
DATABASE_URL=sqlite:///./paperagent.db
```

### 2. å¤šç”¨æˆ·ç”Ÿäº§ç¯å¢ƒ

```bash
# ä½¿ç”¨å¼ºå¯†é’¥
SECRET_KEY=$(python -c "import secrets; print(secrets.token_urlsafe(32))")

# é…ç½®æ•°æ®åº“è¿æ¥æ± 
DATABASE_URL=postgresql://user:pass@db:5432/paperagent?pool_size=20

# å¢åŠ å¹¶å‘
MAX_CONCURRENT_TASKS=20

# å¯ç”¨é€Ÿç‡é™åˆ¶
RATE_LIMIT_ENABLED=true
RATE_LIMIT_PER_MINUTE=100

# ç”Ÿäº§æ¨¡å¼
DEBUG=false
LOG_LEVEL=WARNING
```

### 3. å¼€å‘æµ‹è¯•ç¯å¢ƒ

```bash
# ä½¿ç”¨æœ¬åœ°æ•°æ®åº“
DATABASE_URL=sqlite:///./test.db
REDIS_URL=redis://localhost:6379/0

# è°ƒè¯•æ¨¡å¼
DEBUG=true
LOG_LEVEL=DEBUG

# ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹
DEFAULT_LLM_PROVIDER=ollama
# æˆ–
# DEFAULT_LLM_PROVIDER=openai
# OPENAI_MODEL=gpt-3.5-turbo
```

### 4. ä¸­å›½å¤§é™†ç”¨æˆ·é…ç½®

```bash
# ä½¿ç”¨å›½å†…å¯è®¿é—®çš„æœåŠ¡

# é€‰é¡¹1: ä½¿ç”¨Ollama (æœ¬åœ°)
DEFAULT_LLM_PROVIDER=ollama
OLLAMA_MODEL=qwen2                     # é€šä¹‰åƒé—®

# é€‰é¡¹2: ä½¿ç”¨APIä»£ç†
OPENAI_API_KEY=your-key
# é…ç½®ä»£ç†æœåŠ¡å™¨
HTTP_PROXY=http://127.0.0.1:7890
HTTPS_PROXY=http://127.0.0.1:7890

# æ–‡çŒ®æœç´¢ä½¿ç”¨ä»£ç†
USE_PROXY=true
PROXY_URL=http://127.0.0.1:7890
```

---

## âœ… é…ç½®éªŒè¯

åˆ›å»ºä¸€ä¸ªæµ‹è¯•è„šæœ¬éªŒè¯é…ç½®ï¼š

```python
# test_config.py
import os
from dotenv import load_dotenv

load_dotenv()

print("ğŸ” éªŒè¯é…ç½®...")

# æ£€æŸ¥å¿…éœ€é…ç½®
required = ['DATABASE_URL', 'REDIS_URL', 'DEFAULT_LLM_PROVIDER']
for key in required:
    value = os.getenv(key)
    status = "âœ…" if value else "âŒ"
    print(f"{status} {key}: {value if value else 'NOT SET'}")

# æ£€æŸ¥LLMé…ç½®
provider = os.getenv('DEFAULT_LLM_PROVIDER')
print(f"\nğŸ¤– LLMæä¾›å•†: {provider}")

if provider == 'openai':
    key = os.getenv('OPENAI_API_KEY')
    print(f"{'âœ…' if key and key != 'your_openai_api_key_here' else 'âŒ'} OpenAI API Key")

elif provider == 'anthropic':
    key = os.getenv('ANTHROPIC_API_KEY')
    print(f"{'âœ…' if key and key != 'your_anthropic_api_key_here' else 'âŒ'} Anthropic API Key")

elif provider == 'ollama':
    url = os.getenv('OLLAMA_BASE_URL')
    print(f"âœ… Ollama URL: {url}")
    print("ğŸ’¡ è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ: ollama serve")

print("\nâœ… é…ç½®éªŒè¯å®Œæˆï¼")
```

è¿è¡ŒéªŒè¯ï¼š
```bash
python test_config.py
```

---

## ğŸš€ å¯åŠ¨å‘½ä»¤

### ä½¿ç”¨Dockerï¼ˆæ¨èï¼‰

```bash
# 1. å¤åˆ¶é…ç½®
cp .env.example .env

# 2. ç¼–è¾‘é…ç½®
nano .env

# 3. å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# 4. æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# 5. è®¿é—®åº”ç”¨
# Webç•Œé¢: http://localhost:8501
# APIæ–‡æ¡£: http://localhost:8000/docs
```

### æœ¬åœ°å¼€å‘

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 2. é…ç½®.env
cp .env.example .env
nano .env

# 3. å¯åŠ¨æ•°æ®åº“å’ŒRedis (å¦‚æœä½¿ç”¨Docker)
docker-compose up -d postgres redis

# 4. è¿è¡Œæ•°æ®åº“è¿ç§»
alembic upgrade head

# 5. å¯åŠ¨APIæœåŠ¡
uvicorn paperagent.api.main:app --reload --host 0.0.0.0 --port 8000

# 6. å¯åŠ¨Webç•Œé¢ (æ–°ç»ˆç«¯)
streamlit run paperagent/web/app.py
```

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: å¿˜è®°ä¿®æ”¹é»˜è®¤å¯†é’¥ï¼Ÿ
```bash
# ç”Ÿæˆæ–°å¯†é’¥
python -c "import secrets; print(secrets.token_urlsafe(32))"
# å¤åˆ¶åˆ°.envçš„SECRET_KEY
```

### Q2: Ollamaè¿æ¥å¤±è´¥ï¼Ÿ
```bash
# æ£€æŸ¥Ollamaæ˜¯å¦è¿è¡Œ
ollama list

# å¯åŠ¨Ollama
ollama serve

# æ‹‰å–æ¨¡å‹
ollama pull llama3
```

### Q3: æ•°æ®åº“è¿æ¥å¤±è´¥ï¼Ÿ
```bash
# æ£€æŸ¥Dockerå®¹å™¨
docker-compose ps

# é‡å¯æ•°æ®åº“
docker-compose restart postgres

# æŸ¥çœ‹æ•°æ®åº“æ—¥å¿—
docker-compose logs postgres
```

### Q4: APIå¯†é’¥æ— æ•ˆï¼Ÿ
- æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®å¤åˆ¶ï¼ˆæ— ç©ºæ ¼ï¼‰
- ç¡®è®¤APIè´¦æˆ·æœ‰ä½™é¢
- æ£€æŸ¥å¯†é’¥æƒé™

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé…ç½®é‡åˆ°é—®é¢˜ï¼š

1. æ£€æŸ¥æ—¥å¿—: `docker-compose logs`
2. è¿è¡Œé…ç½®éªŒè¯: `python test_config.py`
3. æŸ¥çœ‹æ–‡æ¡£: `README.md`
4. æäº¤Issue: GitHub Issues

---

**é…ç½®å®Œæˆåï¼Œå³å¯å¼€å§‹ä½¿ç”¨PaperAgentï¼** ğŸ‰ğŸ“šâœ¨
